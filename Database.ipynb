{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page is the scraper for MP. Because there's no API. The only thing I have access to is what's normally viewable online and a json file that contained every single webpage on the MP site. This was scraped in another notebook to only include pages that represented routes. (Other pages included forum pages, area pages, member pages) The processed list was pickled into routes.txt. Next:\n",
    "\n",
    "1. Reference routes.txt\n",
    "2. For each route, download the route page and parse it with BeautifulSoup and a lot of regex\n",
    "3. Put the parsed information in a tuple\n",
    "4. Store the tuple in a new database offline (sqlite)\n",
    "\n",
    "After this is complete, in another notebook we can explore joining this database with a tick list to generate a table containing info for only routes in that ticklist. From there, analysis and visualization can be done, then served up to a website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "There were a bunch of 404s. I probably should have kept track of those as they were happening. moving on...\n",
    "\n",
    "Also should have stored the grade as a string and not a float. 5.10 turned into 5.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sl\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "con = sl.connect('my-test.db')\n",
    "\n",
    "def getPage(url): #take in a URL, return a BS page\n",
    "    page = requests.get(url)\n",
    "    bsPage = BeautifulSoup(page.content, 'html.parser')\n",
    "    return bsPage\n",
    "\n",
    "#Get 1st level area for a given climb url\n",
    "def findArea(routeSoup): #take in a route, return an area url\n",
    "    location = routeSoup.find('a',text = 'All Locations').find_next_siblings()[-1]['href'] #FOUND THE LOCATION!!!! that was so easy!!!\n",
    "    return location\n",
    "\n",
    "def scrapeMeta(routeSoup):\n",
    "    metaEl = routeSoup.find_all('script', type= 'application/ld+json') \n",
    "    meta = [i for i in metaEl]\n",
    "    routeDict = json.loads(meta[0].contents[0])\n",
    "    areaDict = json.loads(meta[1].contents[0])['itemListElement']\n",
    "    \n",
    "    name = routeDict['name']\n",
    "    grade = routeDict['description'].split(' ')[0]\n",
    "    climbtype = routeDict['description'].split(' ')[1:]\n",
    "    climbtype = ' '.join(climbtype)\n",
    "    latitude = routeDict['geo']['latitude']\n",
    "    longitude = routeDict['geo']['longitude']\n",
    "    \n",
    "    return name, grade, climbtype, float(latitude), float(longitude), str(areaDict)\n",
    "\n",
    "def getDescription(routeSoup): #take in route, return description\n",
    "    routeDescription = routeSoup.find_all('div',class_ = 'fr-view')\n",
    "    description = ' '.join([i.text for i in routeDescription]).lower()\n",
    "\n",
    "    return description\n",
    "\n",
    "#  id -url -name -grade -type -area areaDict latitude longitude -description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bug!!! when inserting the 5.10 grade in it cuts out the 0 so it becomes 5.1. \n",
    "\n",
    "Temporary fix: just assume all 5.1s 5.10 for now (pretty safe assumption)\n",
    "The ultimate solution is to rescrape the entire MP site again. :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.10'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the above functions... and the 5.1 to 5.10 fix\n",
    "\n",
    "url = 'https://www.mountainproject.com/route/105717766/3am-crack'\n",
    "routeSoup = getPage(url)\n",
    "\n",
    "name, grade, climbtype, latitude, longitude, areaDict = scrapeMeta(routeSoup)\n",
    "\n",
    "grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.mountainproject.com/route/107033082/cold-terrorists'\n",
    "routeSoup = getPage(url)\n",
    "\n",
    "# scrape the site for meta data (the hierarchy of areas like NA > Utah > SE Utah > Indian Creek, and a description string)\n",
    "metaEl = routeSoup.find_all('script', type= 'application/ld+json') \n",
    "meta = [i for i in metaEl]\n",
    "desc = meta[0].contents\n",
    "areaTree = meta[1].contents\n",
    "routeDict = json.loads(desc[0])\n",
    "areaDict = json.loads(areaTree[0])['itemListElement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'@type': 'ListItem', 'position': 1, 'item': 'https://www.mountainproject.com/route-guide', 'name': 'All Locations'}, {'@type': 'ListItem', 'position': 2, 'item': 'https://www.mountainproject.com/area/105708963/south-dakota', 'name': 'South Dakota'}, {'@type': 'ListItem', 'position': 3, 'item': 'https://www.mountainproject.com/area/112521712/east-side-sd', 'name': 'East Side SD'}, {'@type': 'ListItem', 'position': 4, 'item': 'https://www.mountainproject.com/area/105874281/palisades-state-park', 'name': 'Palisades State Park'}, {'@type': 'ListItem', 'position': 5, 'item': 'https://www.mountainproject.com/area/107033076/adelaide-flow', 'name': 'Adelaide Flow'}]\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of what is contained in the area tree\n",
    "str(areaDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic db functions\n",
    "\n",
    "with open('routes.txt', 'rb') as f:\n",
    "    routes = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "routes = [route[1] for route in routes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table\n",
    "\n",
    "with con: \n",
    "    con.execute(\"DROP TABLE ROUTES\")\n",
    "\n",
    "with con:\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE ROUTES (\n",
    "            id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n",
    "            url TEXT,\n",
    "            name TEXT,\n",
    "            grade FLOAT,\n",
    "            type TEXT,\n",
    "            area TEXT,\n",
    "            areaDict TEXT,\n",
    "            latitude FLOAT,\n",
    "            longitude FLOAT,\n",
    "            description TEXT \n",
    "            \n",
    "        );\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.mountainproject.com/route/117002412/duffys-escape'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes[30655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SCRAPE TIME!! This is the main route scraping section. I hate that this is necessary. \n",
    "\n",
    "n = 1\n",
    "i = 30615 # how many routes to scrape? \n",
    "start = time.time()\n",
    "\n",
    "# \"bookmark\" function. adjust i to start where you last stopped. because this takes several days. \n",
    "with con: \n",
    "    data = con.execute(\"SELECT id FROM ROUTES ORDER BY id DESC LIMIT 1;\")\n",
    "    for row in data:\n",
    "        if row[0]:\n",
    "            i = row[0] + 1\n",
    "\n",
    "for route in routes[i:i+n]:\n",
    "    try: # handle 404s\n",
    "        index = i\n",
    "        routeSoup = getPage(route)\n",
    "        if (routeSoup.find_all('h3',text='The page you\\'re looking for does not exist.')): \n",
    "            print('ERROR 404', i, route)\n",
    "            i+=1\n",
    "            continue\n",
    "    except:\n",
    "        print('ERROR', i, route)\n",
    "        continue\n",
    "    \n",
    "    area = findArea(routeSoup)\n",
    "    description = getDescription(routeSoup)\n",
    "    name, grade, climbtype, latitude, longitude, areaDict = scrapeMeta(routeSoup)\n",
    "    \n",
    "    \n",
    "    routetup = (i, route, name, grade, climbtype, area, areaDict, latitude, longitude, str(description))\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(routetup[0], str(round(time.time()-start)) + 's', routetup[2])\n",
    "    with con:\n",
    "        con.execute('insert into routes (id, url, name, grade, type, area, areaDict, latitude, longitude, description) values(?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',routetup)\n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'id', 'INTEGER', 1, None, 1)\n",
      "(1, 'url', 'TEXT', 0, None, 0)\n",
      "(2, 'name', 'TEXT', 0, None, 0)\n",
      "(3, 'grade', 'FLOAT', 0, None, 0)\n",
      "(4, 'type', 'TEXT', 0, None, 0)\n",
      "(5, 'area', 'TEXT', 0, None, 0)\n",
      "(6, 'areaDict', 'TEXT', 0, None, 0)\n",
      "(7, 'latitude', 'FLOAT', 0, None, 0)\n",
      "(8, 'longitude', 'FLOAT', 0, None, 0)\n",
      "(9, 'description', 'TEXT', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "# sanity check table\n",
    "with con: \n",
    "    data = con.execute('pragma table_info(\"routes\")')\n",
    "    for row in data:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240045, 'North Gully', 'WI3')\n",
      "(240044, 'Mugwort Tea', 'V1')\n",
      "(240043, 'Cumberland SLAPS', 'V4')\n",
      "(240042, 'Su çorbasi', 5.5)\n",
      "(240041, 'Schlitz', '5.10d')\n",
      "(240040, 'Headstrong', '5.11b/c')\n",
      "(240039, 'Mighty Mouse', 'V1')\n",
      "(240038, \"Doctor's Orders\", 'V9+')\n",
      "(240037, 'Back in the Game', 'V0')\n",
      "(240036, 'Clem Fandango', '5.11a')\n",
      "(240035, 'Touchy Feely', '5.10b')\n",
      "(240034, 'A Knight in Climbing Armor', 'V1')\n",
      "(240033, 'Midnight Plowboy', '5.10b')\n",
      "(240032, 'Four Dollar Arete', 'V11')\n",
      "(240031, 'Local Maximum', 'V1')\n",
      "(240030, 'Slash and Burn', 'V4')\n",
      "(240029, 'Icky Yucka', 'V7')\n",
      "(240028, 'West’s Dihedral', 5.7)\n",
      "(240027, 'Goat Crack', '5.10c/d')\n",
      "(240026, 'Minute Man Rocket (Project)', 'V8+')\n",
      "(240025, 'Poison Ivy Arete', 'V0')\n",
      "(240024, 'Moor or Less', 5.3)\n",
      "(240023, 'Oscar the Grouch', 'V11')\n",
      "(240022, 'Swordfish', 'V5-6')\n",
      "(240021, 'Атлантида', '5.10c')\n",
      "(240020, 'Miller Time', 5.6)\n",
      "(240019, 'The Faerie', 'V8')\n",
      "(240018, \"Toog's Trailside Direct\", '5.10b')\n",
      "(240017, 'BB8', 'V3-4')\n",
      "(240016, 'Damascus Road', 'V4')\n",
      "(240015, 'Unknown', '5.11b')\n",
      "(240014, \"Ain't Gonna Be Pretty\", 'V2')\n",
      "(240013, 'The Scoop', 'V2')\n",
      "(240012, 'Mysterious Woman Right', 'V2')\n",
      "(240011, 'Europa Low', 'V7-')\n",
      "(240010, 'La pequena terapia', '5.10b')\n",
      "(240009, 'Witzelsucht', 'V2')\n",
      "(240008, \"Tallman's Route\", 'V2-3')\n",
      "(240007, 'Spotter? I hardly know her', 'V6')\n",
      "(240006, 'Ribeye', 'V2')\n",
      "(240005, 'Twin Cracks', 'V0')\n",
      "(240004, '2067', 'V2')\n",
      "(240003, 'Get to the Top', 'V0')\n",
      "(240002, 'I want my Mommy Couloir', 'WI2')\n",
      "(240001, 'Por Nombrar (Project)', '5.11+')\n",
      "(240000, 'Subase', 'V0')\n",
      "(239999, 'El Santo (Project)', '5.13+')\n",
      "(239998, 'Banana Hammock', 'V2')\n",
      "(239997, 'Desperado Direct', '5.11d')\n",
      "(239996, 'Seamless', 'V3')\n"
     ]
    }
   ],
   "source": [
    "# another sanity check, last 50\n",
    "with con: \n",
    "    data = con.execute(\"SELECT rowid, name, grade FROM ROUTES ORDER BY id DESC LIMIT 50;\")\n",
    "    for row in data:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial attempt at cross ref routes db with tick list\n",
    "\n",
    "ticklist = []\n",
    "\n",
    "con = sl.connect('my-test.db')\n",
    "with con:\n",
    "    data = con.execute('SELECT ticks.rowid, ticks.url, date, grade, status, latitude, longitude FROM ticks INNER JOIN routes ON routes.url = ticks.url where ticks.rowid < 20;')\n",
    "    for row in data:\n",
    "        if row[3] == 5.1:\n",
    "            row2 = list(row)\n",
    "            row2[3] = str('5.10')\n",
    "            row2 = tuple(row2)\n",
    "            ticklist.append(row2)\n",
    "        if row[3] != 5.1: \n",
    "            ticklist.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'https://www.mountainproject.com/route/105740981/rye-crisp', 'Mar 9, 2021', 5.8, 'Lead / Fell/Hung', 42.06738673, -113.70893731), (2, 'https://www.mountainproject.com/route/105803570/pure-palm', 'Mar 9, 2021', '5.11a', 'Solo', 44.36798221, -121.1308092), (3, 'https://www.mountainproject.com/route/109399939/blade-runner', 'Dec 5, 2020', '5.12c', 'Lead / Fell/Hung', 47.43113857, -121.61999578), (4, 'https://www.mountainproject.com/route/111183004/wretched-love-affair', 'Nov 28, 2020', '5.11c', 'Lead / Onsight', 45.53735198, -122.3720833), (5, 'https://www.mountainproject.com/route/111945454/chicago-love-affair', 'Oct 19, 2020', '5.10b', 'Lead / Onsight', 44.36581163, -121.12983902), (6, 'https://www.mountainproject.com/route/105889245/quasar', 'Oct 17, 2020', '5.10a/b', 'Lead / Onsight', 44.36732719, -121.13064751), (7, 'https://www.mountainproject.com/route/105791785/cruel-sister', 'Oct 17, 2020', '5.10a', 'Lead / Onsight', 44.36732719, -121.13064751), (8, 'https://www.mountainproject.com/route/105901816/azog', 'Oct 16, 2020', 5.9, 'Lead / Onsight', 44.3668006, -121.12998275), (9, 'https://www.mountainproject.com/route/109565046/puck', 'Oct 16, 2020', '5.10a/b', 'Lead / Onsight', 44.3668006, -121.12998275), (10, 'https://www.mountainproject.com/route/105803570/pure-palm', 'Oct 16, 2020', '5.11a', 'Lead / Onsight', 44.36798221, -121.1308092), (11, 'https://www.mountainproject.com/route/105803718/gruff', 'Oct 16, 2020', '5.10a', 'Lead / Onsight', 44.36798221, -121.1308092), (12, 'https://www.mountainproject.com/route/105804599/bad-finger', 'Oct 16, 2020', '5.10b', 'Lead / Onsight', 44.36798221, -121.1308092), (13, 'https://www.mountainproject.com/route/105717886/wild-works-of-fire', 'Oct 2, 2020', '5.10', 'Lead / Onsight', 38.03634914, -109.54552445), (14, 'https://www.mountainproject.com/route/105717445/twin-cracks', 'Oct 2, 2020', '5.8+', 'Lead / Onsight', 38.03634914, -109.54552445), (15, 'https://www.mountainproject.com/route/105717766/3am-crack', 'Oct 2, 2020', '5.10', 'Lead / Fell/Hung', 38.03634914, -109.54552445), (16, 'https://www.mountainproject.com/route/105718006/top-40', 'Sep 28, 2020', '5.8+', 'Lead / Onsight', 38.54668821, -109.59961201), (17, 'https://www.mountainproject.com/route/105939455/static-cling', 'Sep 28, 2020', '5.11-', 'Lead / Onsight', 38.54668821, -109.59961201), (18, 'https://www.mountainproject.com/route/106927403/flakes-of-wrath-direct', 'Sep 27, 2020', 5.11, 'TR', 38.54668821, -109.59961201), (19, 'https://www.mountainproject.com/route/105717511/flakes-of-wrath', 'Sep 27, 2020', '5.9+', 'Lead / Onsight', 38.54974434, -109.59724944)]\n"
     ]
    }
   ],
   "source": [
    "print(ticklist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
